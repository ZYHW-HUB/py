import os
import sys
import pymysql
import psutil
from collections import OrderedDict
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as transforms
from torch.optim.lr_scheduler import StepLR
import json
from torch.cuda.amp import autocast, GradScaler
import multiprocessing
import time
from datetime import timedelta, datetime
import csv
from tqdm import tqdm
import numpy as np

# --------------------------
# å…¨å±€é…ç½®ï¼šç›´æ¥è¯»å–ç°åº¦å›¾åƒï¼Œä¸ä½¿ç”¨é¢„å¤„ç†æ•°æ®
# --------------------------
use_preprocessed = False  # å…³é—­é¢„å¤„ç†
# åŸå§‹å›¾åƒç›®å½•ï¼ˆå­˜æ”¾ç°åº¦å›¾åƒæˆ–å½©è‰²å›¾åƒï¼Œç¨‹åºä¼šè½¬æ¢ä¸ºç°åº¦ï¼‰
image_dir = "walk/deeplabv3-master/training_logs/model_eval_seq"
# é¢„å¤„ç†åæ ‡ç­¾ä¿å­˜ç›®å½•ï¼ˆä¸ä½¿ç”¨æ—¶å¯ä»¥å¿½ç•¥ï¼‰
# label_dir = "walk/deeplabv3-master/training_logs/label_npy"

# # --------------------------
# # colormap å®šä¹‰ï¼ˆé¢„å¤„ç†æ—¶ç”¨åˆ°ï¼Œæ­¤å¤„ä¿ç•™ï¼Œå®é™…è¯»å–ç°åº¦å›¾ä¸ä½¿ç”¨è¯¥æ˜ å°„ï¼‰
# # --------------------------
# color_map = {
#     0: [128, 64, 128],   # è·¯é¢
#     1: [244, 35, 232],   # äººè¡Œé“
#     2: [70, 70, 70],     # å»ºç­‘ç‰©
#     3: [102, 102, 156],  # å¢™å£
#     4: [190, 153, 153],  # æ …æ 
#     5: [153, 153, 153],  # æ¡©
#     6: [250, 170, 30],   # äº¤é€šç¯
#     7: [220, 220, 0],    # äº¤é€šæ ‡å¿—
#     8: [107, 142, 35],   # æ¤è¢«
#     9: [152, 251, 152],  # åœ°å½¢
#     10: [70, 130, 180],  # å¤©ç©º
#     11: [220, 20, 60],   # äºº
#     12: [255, 0, 0],     # éª‘è¡Œè€…
#     13: [0, 0, 142],     # æ±½è½¦
#     14: [0, 0, 70],      # å¡è½¦
#     15: [0, 60, 100],    # å·´å£«
#     16: [0, 80, 100],    # ç«è½¦
#     17: [0, 0, 230],     # æ‘©æ‰˜è½¦
#     18: [119, 11, 32],   # è‡ªè¡Œè½¦
#     19: [81, 0, 81]      # å…¶ä»–
# }

# # --------------------------
# # è‡ªå®šä¹‰è½¬æ¢ï¼šRGB -> è¯­ä¹‰æ ‡ç­¾ï¼ˆä»…åœ¨ä¸ä½¿ç”¨é¢„å¤„ç†æ—¶ä½¿ç”¨ï¼‰å¦ä¸€ç§è½¬æ¢æ–¹å¼ï¼ˆæ²¡ä½¿ç”¨è¿‡ï¼‰
# # --------------------------
# class ConvertToLabel(object):
#     def __init__(self, color_map):
#         self.color_map = color_map

#     def __call__(self, image):
#         # image: PIL Imageï¼ŒRGB é¡ºåº
#         np_img = np.array(image)  # (H, W, 3) [R, G, B]
#         # è½¬æ¢ä¸º BGR é¡ºåº
#         np_img = np_img[..., ::-1]  # [B, G, R]
#         h, w, _ = np_img.shape
#         label_img = np.zeros((h, w), dtype=np.int64)
#         # æ ¹æ® colormap è¿›è¡ŒåŒ¹é…
#         for cls, color in self.color_map.items():
#             mask = (np_img[:, :, 0] == color[0]) & (np_img[:, :, 1] == color[1]) & (np_img[:, :, 2] == color[2])
#             label_img[mask] = cls
#         # è¿”å› (1, H, W) float tensor
#         return torch.from_numpy(label_img).unsqueeze(0).float()

# --------------------------
# è‡ªå®šä¹‰è½¬æ¢ï¼šè¿™é‡Œä¸å†è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾ï¼Œè€Œæ˜¯ç›´æ¥è½¬æ¢ä¸ºç°åº¦å›¾çš„ Tensor
# --------------------------
class ConvertToGray(object):
    def __call__(self, image):
        # image: PIL Image
        # è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆå•é€šé“ï¼‰
        image = image.convert("L")
        return transforms.ToTensor()(image)

# --------------------------
# é¢„å¤„ç†å‡½æ•°ï¼ˆä¸ä½¿ç”¨é¢„å¤„ç†æ—¶å¯å¿½ç•¥ï¼‰
# --------------------------
def convert_image_to_label(np_img, color_map):
    """
    å°† BGR é¡ºåºçš„ numpy å›¾åƒè½¬æ¢ä¸ºç±»åˆ«ç´¢å¼•æ ‡ç­¾ï¼ˆé¢„å¤„ç†æ—¶ä½¿ç”¨ï¼‰
    """
    h, w, _ = np_img.shape
    label_img = np.zeros((h, w), dtype=np.int64)
    for cls, color in color_map.items():
        mask = (np_img[:, :, 0] == color[0]) & (np_img[:, :, 1] == color[1]) & (np_img[:, :, 2] == color[2])
        label_img[mask] = cls
    return label_img

def preprocess_all_images(image_dir, save_dir, color_map):
    """
    éå† image_dir ä¸‹æ‰€æœ‰å›¾åƒï¼ˆç°åœ¨ä¸æ˜¯æ‰€æœ‰ï¼‰ï¼Œè½¬æ¢ä¸ºæ ‡ç­¾ï¼ˆç±»åˆ«ç´¢å¼•ï¼‰ï¼Œä¿å­˜ä¸º .npz æ–‡ä»¶è‡³ save_dir
    ï¼ˆé¢„å¤„ç†æµç¨‹ï¼Œä¸ä½¿ç”¨æ—¶å¯å¿½ç•¥ï¼‰
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    # exts = ['.png', '.jpg', '.jpeg', '.bmp']
    # image_files = [f for f in os.listdir(image_dir) if os.path.splitext(f)[1].lower() in exts]
    # ä»…åŒ¹é… _pred.png æ–‡ä»¶
    image_files = [f for f in os.listdir(image_dir) if f.lower().endswith('_pred.png')]
    print(f"å‘ç° {len(image_files)} å¼ å›¾åƒï¼Œå¼€å§‹é¢„å¤„ç†...")
    for filename in tqdm(image_files):
        image_path = os.path.join(image_dir, filename)
        with Image.open(image_path) as img:
            img = img.convert("RGB")
            np_img = np.array(img)  # [R, G, B]
            # è½¬æ¢ä¸º BGR é¡ºåºï¼Œcolormap æŒ‰ BGR å®šä¹‰
            np_img = np_img[..., ::-1]
            label_img = convert_image_to_label(np_img, color_map)
            # è½¬æ¢æ•°æ®ç±»å‹ä¸º uint8ï¼Œå‡å°‘å­˜å‚¨ç©ºé—´ï¼ˆæ²¡è½¬æ¢å‰ç›¸å½“å¤§ï¼Œè½¬æ¢åè®­ç»ƒèµ·æ¥åˆå¾ˆæ…¢ï¼‰
            label_img = label_img.astype(np.uint8)
        # ä¿å­˜æ–‡ä»¶åï¼šä¿æŒåŸå›¾æ–‡ä»¶åï¼ˆå»æ‰æ‰©å±•åï¼‰+ .npz
        base_name = os.path.splitext(filename)[0]
        save_path = os.path.join(save_dir, f"{base_name}.npz")
        np.savez_compressed(save_path, label=label_img)
    print("é¢„å¤„ç†å®Œæˆï¼")

# --------------------------
# 1. æ•°æ®åº“é…ç½®ä¸æ•°æ®è¯»å–
# --------------------------
db_config = {
    "host": "localhost",
    "port": 3306,
    "user": "root",
    "password": "123",
    "database": "scene",
    "charset": "utf8mb4"
}

# æ•°æ®åŠ è½½å‡½æ•°
def load_pair_list(db_config):
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()
        query = "SELECT left_id, right_id, winner FROM pp2 WHERE category = 'safety'"
        cursor.execute(query)
        return [(p[0], p[1], p[2]) for p in cursor.fetchall()]
    except pymysql.MySQLError as e:
        print(f"æ•°æ®åº“é”™è¯¯: {e}")
        return []
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

# åŸå§‹å›¾åƒè·¯å¾„è·å–å‡½æ•°ï¼ˆç”¨äºéé¢„å¤„ç†æ¨¡å¼ï¼‰
def get_image_path(image_id):
    return os.path.join(image_dir, f"{image_id}_pred.png")

# --------------------------
# åˆ›å»ºè¯„åˆ†è¡¨ä¸æ’å…¥è¯„åˆ†å‡½æ•°ï¼ˆä¿®ç€ä¿®ç€è¢«é—²ç½®äº†ï¼‰
# --------------------------
def create_scores_table(db_config):
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS image_scores_safety_S (
                image_id VARCHAR(255),
                score FLOAT,
                split VARCHAR(10),
                PRIMARY KEY (image_id, split)
            )
        """)
        conn.commit()
    except pymysql.MySQLError as e:
        print(f"æ•°æ®åº“é”™è¯¯: {e}")
    finally:
        if 'cursor' in locals():
            cursor.close()
        if 'conn' in locals():
            conn.close()

def insert_scores(db_config, scores, split, conn, cursor, batch_size=1000):
    try:
        query = "INSERT INTO image_scores_safety_S VALUES (%s, %s, %s) ON DUPLICATE KEY UPDATE score=VALUES(score)"
        items = [(str(k), v, split) for k, v in scores.items()]
        for i in range(0, len(items), batch_size):
            cursor.executemany(query, items[i:i+batch_size])
            conn.commit()
    except pymysql.MySQLError as e:
        print(f"æ•°æ®åº“é”™è¯¯: {e.args}")
# # --------------------------
# # 2. æ™ºèƒ½ç¼“å­˜æ•°æ®é›†
# # --------------------------
# class SegmentationPairDataset(Dataset):
#     def __init__(self, pair_list, transform=None):
#         self.pair_list = pair_list
#         self.transform = transform
#         # æ ‡ç­¾æ˜ å°„ï¼š "left" è¡¨ç¤ºå·¦è¾¹è·èƒœï¼Œè½¬æ¢ä¸º 1ï¼›"right" è¡¨ç¤ºå³è¾¹è·èƒœï¼Œè½¬æ¢ä¸º -1ï¼›"equal" è½¬æ¢ä¸º 0
#         self.label_map = {"left": 1, "right": -1, "equal": 0}
#         self.cache = OrderedDict()
#         self.max_cache_size = 800  # æ ¹æ®å†…å­˜å®¹é‡è°ƒæ•´

#     def __len__(self):
#         return len(self.pair_list)

#     def __getitem__(self, idx):
#         if idx in self.cache:
#             self.cache.move_to_end(idx)
#             return self.cache[idx]

#         left_id, right_id, winner = self.pair_list[idx]
#         if use_preprocessed:
#             # é¢„å¤„ç†æ•°æ®åŠ è½½ï¼šç›´æ¥åŠ è½½ .npz æ–‡ä»¶
#             left_label_path = os.path.join(label_dir, f"{left_id}_pred.npz")
#             right_label_path = os.path.join(label_dir, f"{right_id}_pred.npz")
#             if not (os.path.exists(left_label_path) and os.path.exists(right_label_path)):
#                 raise FileNotFoundError(f"ç¼ºå¤±é¢„å¤„ç†æ–‡ä»¶: {left_label_path} æˆ– {right_label_path}")
#             # åŠ è½½ .npz æ–‡ä»¶ï¼Œå¹¶æå– 'label' æ•°ç»„ï¼›ç¡®ä¿å½¢çŠ¶ä¸º (H, W)ï¼Œå† unsqueeze ä¸º (1, H, W)
#             np_left = np.load(left_label_path)['label']
#             np_right = np.load(right_label_path)['label']
#             img_left = torch.from_numpy(np_left).unsqueeze(0).float() if np_left.ndim == 2 else torch.from_numpy(np_left).float()
#             img_right = torch.from_numpy(np_right).unsqueeze(0).float() if np_right.ndim == 2 else torch.from_numpy(np_right).float()
#         else:
#             # æœªé¢„å¤„ç†æ—¶ï¼ŒåŠ è½½åŸå§‹å›¾åƒå¹¶è½¬æ¢
#             left_path = get_image_path(left_id)
#             right_path = get_image_path(right_id)
#             if not all(os.path.exists(p) for p in [left_path, right_path]):
#                 raise FileNotFoundError(f"ç¼ºå¤±æ–‡ä»¶: {left_path} æˆ– {right_path}")
#             img_left = Image.open(left_path).convert("RGB")
#             img_right = Image.open(right_path).convert("RGB")
#             if self.transform:
#                 img_left = self.transform(img_left)
#                 img_right = self.transform(img_right)

#         label = torch.tensor(self.label_map[winner], dtype=torch.float)

#         if len(self.cache) >= self.max_cache_size:
#             self.cache.pop(next(iter(self.cache)))  # åˆ é™¤æœ€æ—©æ’å…¥çš„ç¼“å­˜
#         self.cache[idx] = (img_left, img_right, label, left_id, right_id)
#         return self.cache[idx]

# --------------------------
# 2. æ•°æ®é›†ï¼šç›´æ¥è¯»å–ç°åº¦å›¾åƒ
# --------------------------
class SegmentationPairDataset(Dataset):
    def __init__(self, pair_list, transform=None):
        self.pair_list = pair_list
        self.transform = transform
        # æ ‡ç­¾æ˜ å°„ï¼š "left" è¡¨ç¤ºå·¦è¾¹è·èƒœï¼Œè½¬æ¢ä¸º 1ï¼›"right" è¡¨ç¤ºå³è¾¹è·èƒœï¼Œè½¬æ¢ä¸º -1ï¼›"equal" è½¬æ¢ä¸º 0
        self.label_map = {"left": 1, "right": -1, "equal": 0}
        self.cache = OrderedDict()
        self.max_cache_size = 800  # æ ¹æ®å†…å­˜å®¹é‡è°ƒæ•´

    def __len__(self):
        return len(self.pair_list)

    def __getitem__(self, idx):
        if idx in self.cache:
            self.cache.move_to_end(idx)
            return self.cache[idx]

        left_id, right_id, winner = self.pair_list[idx]
        
        # ç›´æ¥è¯»å–ç°åº¦å›¾åƒ
        left_path = get_image_path(left_id)
        right_path = get_image_path(right_id)
        if not all(os.path.exists(p) for p in [left_path, right_path]):
            raise FileNotFoundError(f"ç¼ºå¤±æ–‡ä»¶: {left_path} æˆ– {right_path}")
        img_left = Image.open(left_path).convert("L")  # è½¬æ¢ä¸ºç°åº¦å›¾
        img_right = Image.open(right_path).convert("L")
        if self.transform:
            img_left = self.transform(img_left)
            img_right = self.transform(img_right)

        label = torch.tensor(self.label_map[winner], dtype=torch.float)

        if len(self.cache) >= self.max_cache_size:
            self.cache.pop(next(iter(self.cache)))  # åˆ é™¤æœ€æ—©æ’å…¥çš„ç¼“å­˜
        self.cache[idx] = (img_left, img_right, label, left_id, right_id)
        return self.cache[idx]

# --------------------------
# 3. å†…å­˜ä¼˜åŒ–æ¨¡å‹
# --------------------------
class SiameseNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        # æ³¨æ„ï¼šè¾“å…¥é€šé“ä¸º 1ï¼Œå› ä¸ºè¯»å–çš„æ˜¯ç°åº¦å›¾åƒ
        self.conv = nn.Sequential(
            nn.Conv2d(1, 32, 3, 1, 1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2)
        )
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Sequential(nn.Linear(128, 128), nn.ReLU(), nn.Linear(128, 1))
        
        self._init_weights()
        torch.backends.cudnn.benchmark = True
        torch.backends.cuda.matmul.allow_tf32 = True

    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    def forward_once(self, x):
        x = x.contiguous(memory_format=torch.channels_last)
        # å¦‚ä¸éœ€è¦èŠ‚çœæ˜¾å­˜ï¼Œå¯ä¸ä½¿ç”¨ checkpointï¼ˆæ­¤å¤„æ³¨é‡Šæ‰ï¼‰
        # x = torch.utils.checkpoint.checkpoint(self.conv, x)
        x = self.conv(x)
        x = self.avgpool(x)
        return self.fc(x.flatten(1))

    def forward(self, x1, x2):
        return self.forward_once(x1), self.forward_once(x2)

# --------------------------
# 4. åŠ¨æ€æŸå¤±è®¡ç®—
# --------------------------
def compute_loss(r1, r2, label, margin=0.5):
    loss = torch.tensor(0.0, device=r1.device)
    margin_loss = nn.MarginRankingLoss(margin=margin, reduction="sum")
    mse_loss = nn.MSELoss(reduction="sum")

    pos_mask = label == 1
    neg_mask = label == -1
    eq_mask = label == 0

    if pos_mask.any():
        loss += margin_loss(r1[pos_mask], r2[pos_mask], torch.ones_like(r1[pos_mask]))
    if neg_mask.any():
        loss += margin_loss(r2[neg_mask], r1[neg_mask], torch.ones_like(r2[neg_mask]))
    if eq_mask.any():
        loss += mse_loss(r1[eq_mask], r2[eq_mask])

    return loss / label.numel()

# --------------------------
# 5. è‡ªé€‚åº”ç¡¬ä»¶é…ç½®
# --------------------------
def hardware_config():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # æ ¹æ® GPU/CPU å†…å­˜åŠ¨æ€è®¡ç®—æ‰¹æ¬¡å¤§å°
    if device.type == "cuda":
        total_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3
        batch_size = min(64, int(total_mem * 0.7 // 0.25))
    else:
        avail_mem = psutil.virtual_memory().available / 1024**3
        batch_size = min(32, int(avail_mem * 0.6 // 0.15))
    
    grad_accum_steps = 2 if batch_size < 16 else 1
    
    return (
        device,
        max(batch_size, 8),  # ä¿è¯æœ€å°æ‰¹æ¬¡å¤§å°
        min(4, os.cpu_count() // 2),  # å·¥ä½œè¿›ç¨‹æ•°
        grad_accum_steps
    )

# --------------------------
# 6. è®­ç»ƒæµç¨‹
# --------------------------
if __name__ == '__main__':
    # # å¦‚æœä½¿ç”¨é¢„å¤„ç†æ•°æ®ï¼Œæ£€æŸ¥é¢„å¤„ç†ç›®å½•æ˜¯å¦å­˜åœ¨æˆ–ä¸ºç©ºï¼Œè‹¥éœ€è¦åˆ™é¢„å¤„ç†
    # if use_preprocessed:
    #     if not os.path.exists(label_dir) or len(os.listdir(label_dir)) == 0:
    #         print("é¢„å¤„ç†æ•°æ®ä¸å­˜åœ¨ï¼Œå¼€å§‹é¢„å¤„ç†...")
    #         preprocess_all_images(image_dir, label_dir, color_map)

    # æ—¥å¿—ä¸æ¨¡å‹ä¿å­˜ç›®å½•é…ç½®
    log_dir = "walk/deeplabv3-master/training_logs/siamese6"
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"training_log_{datetime.now().strftime('%Y%m%d%H%M')}.csv")
    model_dir = os.path.join(log_dir, "saved_models")
    os.makedirs(model_dir, exist_ok=True)

    # åˆå§‹åŒ–æœ€ä½³æŒ‡æ ‡è·Ÿè¸ªå™¨
    best_metrics = {
        'epoch': 0,
        'val_loss': float('inf'),
        'val_acc': 0.0,
        'train_acc': 0.0
    }

    # åˆ›å»º CSV æ—¥å¿—æ–‡ä»¶å¤´
    with open(log_file, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow([
            'epoch', 'train_loss', 'val_loss', 
            'train_acc', 'val_acc', 'epoch_time',
            'model_path'
        ])

    multiprocessing.freeze_support()

    # åˆå§‹åŒ–ç¡¬ä»¶é…ç½®
    device, batch_size, num_workers, grad_accum = hardware_config()
    # # è‹¥ä¸ä½¿ç”¨é¢„å¤„ç†ï¼Œå¯ä½¿ç”¨è½¬æ¢ï¼ˆæ­¤å¤„ä»…ä½œå¤‡ç”¨ï¼Œä¸ä¼šåœ¨é¢„å¤„ç†æ¨¡å¼ä¸‹ä½¿ç”¨ï¼‰
    # transform = transforms.Compose([
    #     transforms.Resize((128, 128)),
    #     ConvertToLabel(color_map)
    # ])
    # ä½¿ç”¨è½¬æ¢ï¼šè°ƒæ•´å°ºå¯¸å¹¶è½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆå•é€šé“ï¼‰
    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor()  # è‹¥å›¾åƒå·²è½¬ä¸ºç°åº¦ï¼ŒToTensor()ä¼šè‡ªåŠ¨ç”Ÿæˆå•é€šé“ tensor
    ])

    # æ•°æ®åŠ è½½
    pair_list = load_pair_list(db_config)
    # dataset = SegmentationPairDataset(pair_list, transform if not use_preprocessed else None)
    dataset = SegmentationPairDataset(pair_list, transform)
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_set, val_set = random_split(dataset, [train_size, val_size])

    train_loader = DataLoader(
        train_set,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        generator=torch.Generator(device='cpu'),
        persistent_workers=True,
        drop_last=True,
        prefetch_factor=1  # é™ä½é¢„åŠ è½½ï¼Œå‡å°‘å†…å­˜å‹åŠ›
    )

    val_loader = DataLoader(
        val_set,
        batch_size=max(batch_size // 2, 8),
        shuffle=False,
        num_workers=max(1, num_workers // 2),
        pin_memory=True
    )

    # æ¨¡å‹åˆå§‹åŒ–å¹¶åŠ è½½åˆ°è®¾å¤‡ï¼ˆä½¿ç”¨ channel_last å†…å­˜æ ¼å¼ï¼‰
    model = SiameseNetwork().to(device, memory_format=torch.channels_last)
    
    # å¦‚æœæ”¯æŒ torch.compile ä¸”é Windowsï¼Œåˆ™ç¼–è¯‘æ¨¡å‹ä»¥æå‡é€Ÿåº¦
    if sys.platform != "win32" and hasattr(torch, "compile"):
        model = torch.compile(model)
    else:
        print("torch.compile åœ¨ Windows å¹³å°ä¸å¯ç”¨ï¼Œè·³è¿‡ç¼–è¯‘ã€‚")
    
    optimizer = optim.Adam(model.parameters(), lr=1e-3)
    scaler = GradScaler(enabled=torch.cuda.is_available())
    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)
    model_save_path = os.path.join(model_dir, "siamese_model.pth")
    scores_save_path = os.path.join(log_dir, "scores.json")
    create_scores_table(db_config)

    # æ•°æ®åº“è¿æ¥
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()
    except pymysql.MySQLError as e:
        print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        exit(1)

    # è®­ç»ƒå¾ªç¯
    total_start = time.time()
    for epoch in range(10):
        epoch_start = time.time()
        model.train()
        optimizer.zero_grad()
        
        # åˆå§‹åŒ–è®­ç»ƒç»Ÿè®¡æŒ‡æ ‡
        running_loss = 0.0
        running_correct = 0  # è®­ç»ƒæ­£ç¡®æ ·æœ¬æ•°
        total_samples = 0    # è®­ç»ƒæœ‰æ•ˆæ ·æœ¬æ•°
        train_scores = {}

        # è®­ç»ƒé˜¶æ®µ
        for i, (img_l, img_r, labels, ids_l, ids_r) in enumerate(tqdm(train_loader, desc=f"Epoch {epoch+1}", leave=False)):
            # æ•°æ®ä¼ è¾“ï¼šé‡‡ç”¨éé˜»å¡ä¼ è¾“å’Œ channels_last æ ¼å¼
            img_l = img_l.to(device, non_blocking=True, memory_format=torch.channels_last)
            img_r = img_r.to(device, non_blocking=True, memory_format=torch.channels_last)
            labels = labels.to(device, non_blocking=True)

            with autocast(enabled=torch.cuda.is_available()):
                out1, out2 = model(img_l, img_r)
                loss = compute_loss(out1, out2, labels) / grad_accum

                with torch.no_grad():
                    preds = torch.where(out1 > out2, 1, -1)
                    mask = labels != 0  # æ’é™¤å¹³å±€æ ·æœ¬
                    correct = (preds.flatten()[mask] == labels[mask]).sum().item()
                    running_correct += correct
                    total_samples += mask.sum().item()

            if torch.cuda.is_available():
                scaler.scale(loss).backward()
                if (i + 1) % grad_accum == 0:
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()
            else:
                loss.backward()
                if (i + 1) % grad_accum == 0:
                    optimizer.step()
                    optimizer.zero_grad()

            running_loss += loss.item()

        train_acc = running_correct / total_samples if total_samples > 0 else 0.0

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0  # éªŒè¯æ­£ç¡®æ ·æœ¬æ•°
        val_total = 0    # éªŒè¯æœ‰æ•ˆæ ·æœ¬æ•°
        val_scores = {}
        
        with torch.inference_mode(), autocast(enabled=torch.cuda.is_available()):
            for img_l, img_r, labels, ids_l, ids_r in tqdm(val_loader, desc="Validation", leave=False):
                img_l = img_l.to(device, non_blocking=True, memory_format=torch.channels_last)
                img_r = img_r.to(device, non_blocking=True, memory_format=torch.channels_last)
                labels = labels.to(device, non_blocking=True)
                
                out1, out2 = model(img_l, img_r)
                val_loss += compute_loss(out1, out2, labels).item()

                with torch.no_grad():
                    preds = torch.where(out1 > out2, 1, -1)
                    mask = labels != 0  # æ’é™¤å¹³å±€æ ·æœ¬
                    val_correct += (preds.flatten()[mask] == labels[mask]).sum().item()
                    val_total += mask.sum().item()

        avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0.0
        val_acc = val_correct / val_total if val_total > 0 else 0.0

        # ä¿å­˜æ¯ä¸ª epoch çš„æ¨¡å‹
        epoch_model_path = os.path.join(model_dir, f"epoch_{epoch+1}.pth")
        torch.save(model.state_dict(), epoch_model_path)

        # æ›´æ–°æœ€ä½³æ¨¡å‹æŒ‡æ ‡
        if val_acc > best_metrics['val_acc'] or (val_acc == best_metrics['val_acc'] and avg_val_loss < best_metrics['val_loss']):
            best_metrics.update({
                'epoch': epoch + 1,
                'val_loss': avg_val_loss,
                'val_acc': val_acc,
                'train_acc': train_acc
            })
            torch.save(model.state_dict(), os.path.join(model_dir, "best_model.pth"))

        with open(log_file, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                epoch + 1, 
                running_loss / len(train_loader) if len(train_loader) > 0 else 0.0,
                avg_val_loss,
                train_acc,
                val_acc,
                time.time() - epoch_start,
                epoch_model_path
            ])

        epoch_time = time.time() - epoch_start
        print(f"Epoch {epoch+1}/10 | Train Loss: {running_loss/len(train_loader):.4f} | Val Loss: {avg_val_loss:.4f} | Train Acc: {train_acc:.2%} | Val Acc: {val_acc:.2%} | Time: {timedelta(seconds=int(epoch_time))}")

        scheduler.step()

    print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼šEpoch {best_metrics['epoch']}")
    print(f"â— éªŒè¯é›†æŸå¤±: {best_metrics['val_loss']:.4f}")
    print(f"â— è®­ç»ƒå‡†ç¡®ç‡: {best_metrics['train_acc']:.2%}")
    print(f"â— éªŒè¯å‡†ç¡®ç‡: {best_metrics['val_acc']:.2%}")
    print(f"â— æ¨¡å‹è·¯å¾„: {os.path.join(model_dir, 'best_model.pth')}")

    total_time = timedelta(seconds=int(time.time() - total_start))
    print(f"\nè®­ç»ƒå®Œæˆï¼æ€»è€—æ—¶: {total_time}")
    
    cursor.close()
    conn.close()
    
    with open(scores_save_path, 'w') as f:
        json.dump({'train_scores': train_scores, 'val_scores': val_scores}, f)
        print(f"è¯„åˆ†å·²ä¿å­˜åˆ° {scores_save_path}")
